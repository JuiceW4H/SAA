## DynamoDB Architecture

* DynamoDB is NoSQL, wide column, Database-as-a-Service product within AWS.
* An AWS Public Service.
* Capable of handling simple Key/Value data or data with a structure like the DocumentDB model.
* Manual/Automatic provisioned performance going in/out or On-Demand.
* Regionally resilient and optionally Globally Resilient.
* Data is replicated across multiple storage nodes by Default.
* Allows for backups, point-in-time recovery, and encryption at rest.

Tables
	\- the base entity inside the DynamoDB product.
	\- a grouping of items which all share the same primary key.

Items
	\- are how you manage your data within that table.
	\- values of rows.
	\- can have a max of 400KB in size.

**2 Types of Primary Keys**

1. Simple Primary Key (Partition Key)
2. Composite Primary Key (Partition and Sort Key)

* Each item must have a unique value for PK and SK.
* DynamoDB has no rigid attribute schema.

**2 Types of Capacity**

1. Provisioned Capacity
	\- you need to explicitly set the capacity values on a per table basis.

2. On-Demand Capacity

* Capacity means speed in DynamoDB.
* (Writes) 1 WCU = 1KB per second
* (Reads) 1 RCU = 4KB per second

**2 Types of Backups**

1. On-Demand Backups
	\- manual full backup retained until you manually remove that backup.
	\- can restore to the same region or cross-region.
	\- allows for table restoration with or without indexes.
	\- has the ability to adjust the encryption settings as part of the restore.

2. Point-In-Time Recovery (PITR)
	\- disabled by Default.
	\- can be enabled on a per table basis.
	\- continuous stream of backups for over a 35-day window.
	\- 1 second granularity.

![NoSQL Databases & DynamoDB-08-09-2024](images/NoSQL%20Databases%20&%20DynamoDB-08-09-2024.png)

## DynamoDB - Operations, Consistency, and Performance

* Auto Scaling is not enabled by Default.

**Capacity Types**

1. On-Demand
	\- designed for unknown or unpredictable level of load.
	\- price per million R or W units.

2. Provisioned
	\- you set a capacity value for reads and writes on a per table basis.

* Every operation in a DynamoDB table consumes at least 1 RCU/WCU.
* (Writes) 1 WCU = 1KB per second
* (Reads) 1 RCU = 4KB per second
* Every table has a RCU and WCU burst pool (300 Seconds) of the units set on the table.

Query
	\- one way that you can retrieve data.
	\- only accepts a single PK value and optionally a single or a range of SK.

![NoSQL Databases & DynamoDB-08-09-2024-1](images/NoSQL%20Databases%20&%20DynamoDB-08-09-2024-1.png)

* Capacity consumed is the size of all returned items.
* Filtering discards data, but still consumes the full rounded up Capacity Unit.

Scan
	\- least efficient, but most flexible operation.
	\- moves through the table item by item.
	\- consumes CU for every item scanned through.

![NoSQL Databases & DynamoDB-08-09-2024-2](images/NoSQL%20Databases%20&%20DynamoDB-08-09-2024-2.png)

**Consistency Model**

![NoSQL Databases & DynamoDB-08-09-2024-3](images/NoSQL%20Databases%20&%20DynamoDB-08-09-2024-3.png)

* Writes always occur on the Leader Storage Node.
* Leader node replicates data to other nodes.

Strongly Consistent Read
	\- always uses the Leader Node for up to date copy.

Eventually Consistent Read
	\- reads are half the price of Strongly Consistent reads.
	\- gets twice as much reads for each individual read capacity units.

**WCU Calculation**

![NoSQL Databases & DynamoDB-08-09-2024-4](images/NoSQL%20Databases%20&%20DynamoDB-08-09-2024-4.png)

**RCU Calculation**

![NoSQL Databases & DynamoDB-08-09-2024-5](images/NoSQL%20Databases%20&%20DynamoDB-08-09-2024-5.png)

## DynamoDB Local and Global Secondary Indexes

* Indexes are a way to improve the efficiency of data retrieval operations within DynamoDB.
* Indexes are alternative views on table data.
* When creating them you have the ability to choose which attributes from the base table are projected into them.

1. Local Secondary Indexes (LSI)
	\- allows you to create a different view using a different/alternative SK.
	\- must be created with the table itself.
	\- maximum of 5 LSIs per table.
	\- shared the RCU and WCU with the table.

Attributes: ALL, KEYS_ONLY, & INCLUDE

![NoSQL Databases & DynamoDB-08-09-2024-6](images/NoSQL%20Databases%20&%20DynamoDB-08-09-2024-6.png)

* Items from the base table which have value for the attribute that we define as the new SK are present in the index.

2. Global Secondary Indexes (GSI)
	\- allows a view with a different PK and SK.
	\- can be created at any time.
	\- Default limit of 20 GSIs per table.
	\- have their own RCU and WCU capacity values.

Attributes: ALL, KEYS_ONLY, & INCLUDE

![NoSQL Databases & DynamoDB-08-09-2024-7](images/NoSQL%20Databases%20&%20DynamoDB-08-09-2024-7.png)

* Items from the base table which have value for the attribute that we define as the new PK, and optionally SK, are present in the index.
* GSIs are always eventually consistent.
* Replication between base and GSI is asynchronous.

![NoSQL Databases & DynamoDB-08-09-2024-8](images/NoSQL%20Databases%20&%20DynamoDB-08-09-2024-8.png)

* Use GSIs as Default, but choose LSI if strong consistency is required.

High-Cardinality Attribute
	\- refers to Partition Keys having a large number of distinct values for each item.

* HCA allows more requests to spread across the partitioned space.

## DynamoDB - Streams and Lambda Triggers

* DynamoDB Stream is a time ordered list of changes to items inside a DynamoDB table.

Stream
	\- a 24-hour rolling window of changes.
	\- are enabled on a per table basis.
	\- records Inserts, Updates, and Deletes.

**View Types on Streams**

![NoSQL Databases & DynamoDB-08-09-2024-9](images/NoSQL%20Databases%20&%20DynamoDB-08-09-2024-9.png)

1. KEYS_ONLY
	\- only records the PK and optionally SK value for the item which has changed.

2. NEW_IMAGE
	\- records the item after the change.

3. OLD_IMAGE
	\- records the item before the change.

4. NEW_AND_OLD_IMAGES
	\- records the item state before and after the changes.

Triggers
	\- allow for actions to take place in the event of a change in data.
	\- item changes generates an event.

![NoSQL Databases & DynamoDB-08-09-2024-10](images/NoSQL%20Databases%20&%20DynamoDB-08-09-2024-10.png)

* That event contains the data which changed.
* An action is taken using that data.
* Use Streams and Lambda together to implement a Trigger/Event-driven Architecture.

## DynamoDB Global Tables

* Global Tables provide multi-master replication and cross-region replication.
* Allows for read and write replication between all tables that are part of a Global Table.
* Tables created in multiple regions and added to the same Global Table (becoming replica tables).

Last Writer Wins
	\- used for conflict resolution.
	\- meaning DynamoDB will pick the most recent write to replicate/overwrite to other tables that are part of the Global Table.

![NoSQL Databases & DynamoDB-08-09-2024-11](images/NoSQL%20Databases%20&%20DynamoDB-08-09-2024-11.png)

* Strongly consistent read only in the same region as writes, otherwise eventual consistency.

## DynamoDB - Accelerator (DAX)

* DAX is an in-memory cache that is designed to reduce the response time of read operations from milliseconds to microseconds.

**Traditional Caches vs DAX**

![NoSQL Databases & DynamoDB-08-09-2024-12](images/NoSQL%20Databases%20&%20DynamoDB-08-09-2024-12.png)

**DAX Architecture**

![NoSQL Databases & DynamoDB-08-09-2024-13](images/NoSQL%20Databases%20&%20DynamoDB-08-09-2024-13.png)

* DAX operates from within a VPC, and designed to be deployed into multiple AZs in that VPC.
* DAX is a cluster service meaning nodes are placed in different AZs.
* There is a Primary Node (R&W) which replicates out to other nodes that are Replica (Read Replicas).
* Supports read caching of items and query/scan results.
* If a Cache Miss occurs data is written to the Primary Node of the cluster then replicated to the replica nodes.

**2 Caches Maintained by DAX**

1. Item Cache
	\- holds results of GetItem or BatchGetItem operations.
	\- caches of single items directly retrieved.

2. Query Cache
	\- holds items based on Query/Scan results and parameters used in those operation/s.

* Uses write-through caching.

Write-Through Caching
	\- data is written into DAX at the same time as it is being written into the database.

![NoSQL Databases & DynamoDB-08-09-2024-14](images/NoSQL%20Databases%20&%20DynamoDB-08-09-2024-14.png)

## DynamoDB TTL

![NoSQL Databases & DynamoDB-08-09-2024-15](images/NoSQL%20Databases%20&%20DynamoDB-08-09-2024-15.png)

* TTL Feature allows you to define a Timestamp which allows items in a table to be automatically deleted at a certain point in time.
* A Date and Time (in seconds) is specified per item when it will be deleted.

**How it works**
	\
* Enable TTL on a table.
* Pick an attribute, which would contain a number (value in seconds), to be used for the TTL processes.
* Number value would be in terms of seconds since the Epoch (January 1, 1970) up to the date you want the item to expire (in seconds).

## Amazon Athena

* Athena is a serverless Interactive Querying Service.
* It can take data stored in S3 and perform ad-hoc queries on that data.
* It allows SQL-like queries on data without transforming source data.
* Pay only for the data consume while running the query.
* Original data in S3 is never changed.

Schema-on-Read
	\- table-like translation.
	\- data is conceptually streamed through the schema/table-structure you defined while being queried.

**Athena Architecture**
![NoSQL Databases & DynamoDB-08-09-2024-16](images/NoSQL%20Databases%20&%20DynamoDB-08-09-2024-16.png)

* Supports standard formats of Structured, Semi-Structured, and Unstructured data.
* In Athena, you’re defining a way to take the original data and present it in a way that you want which allows you to run queries against these tables.
* Tables are defined in-advance. As data is read through it’s transformed on the fly into that table structure.
* A bucket is also needed for the output of Athena (Query Result Location).

Use Case

* Queries where loading/transformation isn’t desired.
* Occasional/Ad-hoc queries on data in S3.
* Serverless querying scenarios (cost conscious)
* Querying AWS logs

Athena Federated Query
	\- capability of Athena to query non-S3 data sources.
	\- uses data source connectors.

Data source connector
	\- a piece of code that can translate between a target data source which isn’t S3 and Athena.

## ElastiCache

![NoSQL Databases & DynamoDB-08-09-2024-17](images/NoSQL%20Databases%20&%20DynamoDB-08-09-2024-17.png)

* ElastiCache is an in-memory database for applications which have high-end performance requirements.
* Can be used to cache data for read heavy workloads with low latency requirements.
* Can be used to store Session Data (Stateless Servers).

**2 Different Engines Provided by ElastiCache**

1. Redis
2. Memcached

**ElastiCache - Cache Architecture**

![NoSQL Databases & DynamoDB-08-09-2024-18](images/NoSQL%20Databases%20&%20DynamoDB-08-09-2024-18.png)

* An in-memory cache allows cost effective scaling of read-heavy workloads and performance improvement at scale.

**ElastiCache - Session State Data Architecture**

![NoSQL Databases & DynamoDB-08-09-2024-19](images/NoSQL%20Databases%20&%20DynamoDB-08-09-2024-19.png)

**Redis vs MemcacheD**

![NoSQL Databases & DynamoDB-08-09-2024-20](images/NoSQL%20Databases%20&%20DynamoDB-08-09-2024-20.png)

**MemcacheD**
	\- supports simple data structures only (Strings).
	\- no replication.
	\- supports Multiple Nodes (Sharding).
	\- multi-threaded by design.

Sharding
	\- storing certain data in specific node/s and others in another.

Multi-Threaded
	\- can take better advantage of multi-core CPUs.

**Redis**
	\- supports advanced types of data structures (Lists, Sets,Sorted Sets, Hashes, Bit Arrays, and many more).
	\- supports Multi-AZ replication.
	\- supports backups and restores.
	\- has Transactions feature.

Transactions
	\- it is able to treat multiple operations as one.

## Redshift Architecture

* Redshift is a petabyte-scale data warehouse.
* An Online Analytical Processing (OLAP) Database (Column Based).
* It is a VPC service.
* Pay as you use and uses a similar structure to RDS.
* SQL-like interface JBDC/ODBC connections.

Data Warehouse
	\- a location where many different operational DBs can pump data into for long term analysis and trending.

Online Analytical Processing (OLAP)
	\- designed for complex queries to analyze aggregated historical data from OLTP systems.

Redshift Spectrum
	\- allows for querying of data on S3 without loading it into Redshift in advanced.

Federated Query
	\- allows you to directly query data that’s stored in other DBs.

**Redshift Architecture**

![NoSQL Databases & DynamoDB-08-09-2024-21](images/NoSQL%20Databases%20&%20DynamoDB-08-09-2024-21.png)

* Server based product
* Redshift uses a cluster architecture.
* Runs in 1 AZ.
* Data is replicated to 1 additional node.
* Automatic backups happen to S3 by Default around every 8 hours or every 5GB of data written to the cluster with a configurable retention period.
* You can also create Manual Snapshots to S3.

Leader Node
	\- you interact most with.
	\- manages communications with client programs and all communications with the compute nodes.

Compute Nodes
	\- runs the queries assigned by the Leader Node and stores the data loaded into the system.
	\- it is partitioned into slices.

* A Node might have 2, 4, 16, or 32 slices.
* Depends of the resource capacity of that node.

Slices
	\- each is allocated a portion of the nodes memory and disc space.
	\- processes a portion of the workload assigned to the Compute Node.

* By Default, Redshift uses Public Routes for traffic when communicating with external services.

Enhanced VPC Routing
	\- allows for Advanced/Custom Networking Control.
	\- when enabled traffic will instead be routed based on your VPC networking configuration.
	\- meaning can be controlled by SGs, NACLs, and etc.

## Redshift DR and Resilience

![NoSQL Databases & DynamoDB-08-09-2024-22](images/NoSQL%20Databases%20&%20DynamoDB-08-09-2024-22.png)

* Utilize S3 for backups in the form of Snapshots.
* Redshift can be configured to copy snapshots to another region for DR - with a seperate configurable retention period.

**2 Types of Backups Supported**

1. Automatic Backups
	\- backups once every 8 hours or every 5GB of data change.
	\- has a 1 day retention period by Default.
	\- configurable retention period of up to 35 days.

2. Manual Backups
	\- performed explicitly by a person or a script or a management application.
	\- no retention periods.

